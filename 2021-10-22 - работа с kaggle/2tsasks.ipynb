{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T09:54:45.883894Z",
     "iopub.status.busy": "2021-10-22T09:54:45.883555Z",
     "iopub.status.idle": "2021-10-22T09:54:47.433325Z",
     "shell.execute_reply": "2021-10-22T09:54:47.432429Z",
     "shell.execute_reply.started": "2021-10-22T09:54:45.883809Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T09:54:47.435211Z",
     "iopub.status.busy": "2021-10-22T09:54:47.434968Z",
     "iopub.status.idle": "2021-10-22T09:54:47.439665Z",
     "shell.execute_reply": "2021-10-22T09:54:47.438852Z",
     "shell.execute_reply.started": "2021-10-22T09:54:47.435185Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "device = torch.device(dev) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T09:54:49.659700Z",
     "iopub.status.busy": "2021-10-22T09:54:49.659156Z",
     "iopub.status.idle": "2021-10-22T09:55:03.568441Z",
     "shell.execute_reply": "2021-10-22T09:55:03.567690Z",
     "shell.execute_reply.started": "2021-10-22T09:54:49.659662Z"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = \"../input/cian-datafest-2019\"\n",
    "train_dir = os.path.join(base_dir, \"train.zip\")\n",
    "test_dir = os.path.join(base_dir, \"test.zip\")\n",
    "\n",
    "with zipfile.ZipFile(train_dir,\"r\") as z:\n",
    "    z.extractall()\n",
    "    \n",
    "with zipfile.ZipFile(test_dir,\"r\") as z:\n",
    "    z.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T09:55:03.569961Z",
     "iopub.status.busy": "2021-10-22T09:55:03.569745Z",
     "iopub.status.idle": "2021-10-22T09:55:03.952387Z",
     "shell.execute_reply": "2021-10-22T09:55:03.951529Z",
     "shell.execute_reply.started": "2021-10-22T09:55:03.569936Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize((56,56)), transforms.ToTensor()])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder('./train', \n",
    "                                              transform=transform)\n",
    "\n",
    "trainset = torch.utils.data.Subset(train_data, list(range(0, len(train_data), 6)))\n",
    "\n",
    "train_set, val_set = torch.utils.data.random_split(trainset, [6000, 3221])\n",
    "train_data_loader = torch.utils.data.DataLoader(train_set, batch_size=500, \n",
    "                                                shuffle=True, num_workers=2)\n",
    "val_data_loader = torch.utils.data.DataLoader(val_set, batch_size=500, \n",
    "                                              shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте сверточную нейронную сеть, которая решала бы задачу предсказания, снаружи или внутри помещения сделана фотография."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T09:59:47.862692Z",
     "iopub.status.busy": "2021-10-22T09:59:47.862356Z",
     "iopub.status.idle": "2021-10-22T09:59:47.874757Z",
     "shell.execute_reply": "2021-10-22T09:59:47.873868Z",
     "shell.execute_reply.started": "2021-10-22T09:59:47.862656Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=8, kernel_size=5, stride=1, padding=1)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=4, stride=1)\n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=2, stride=2, padding=1)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=32, out_channels=128, kernel_size=7)\n",
    "        self.pooling_layer1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.pooling_layer2 = nn.AvgPool2d(kernel_size=2)\n",
    "        \n",
    "        self.linear_layer1 = nn.Linear(in_features=128, out_features=1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        output_1 = self.relu(self.conv_layer1(x))\n",
    "        output_2 = self.pooling_layer1(output_1)\n",
    "        output_3 = self.relu(self.conv_layer2(output_2))\n",
    "        output_4 = self.pooling_layer2(output_3)\n",
    "        output_5 = self.relu(self.conv_layer3(output_4))\n",
    "        output_6 = self.relu(self.conv_layer4(output_5))\n",
    "        output_7 = torch.flatten(output_6, 1)\n",
    "        \n",
    "        output = self.linear_layer1(output_7)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T09:59:48.816276Z",
     "iopub.status.busy": "2021-10-22T09:59:48.815298Z",
     "iopub.status.idle": "2021-10-22T09:59:48.825321Z",
     "shell.execute_reply": "2021-10-22T09:59:48.824448Z",
     "shell.execute_reply.started": "2021-10-22T09:59:48.816217Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T09:59:49.703789Z",
     "iopub.status.busy": "2021-10-22T09:59:49.703482Z",
     "iopub.status.idle": "2021-10-22T09:59:49.708616Z",
     "shell.execute_reply": "2021-10-22T09:59:49.707658Z",
     "shell.execute_reply.started": "2021-10-22T09:59:49.703759Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь (loss function + optimizer)\n",
    "# optimizer = Adam(0.001)\n",
    "# loss function = BCEWithLogitsLoss\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T09:59:50.571839Z",
     "iopub.status.busy": "2021-10-22T09:59:50.571028Z",
     "iopub.status.idle": "2021-10-22T10:00:16.547097Z",
     "shell.execute_reply": "2021-10-22T10:00:16.546067Z",
     "shell.execute_reply.started": "2021-10-22T09:59:50.571791Z"
    }
   },
   "outputs": [],
   "source": [
    "# обучение\n",
    "torch.manual_seed(10)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "total_step = len(train_data_loader)\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_data_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.reshape(len(labels), 1)\n",
    "        labels = labels.type(torch.FloatTensor)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "               .format(epoch+1, epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T10:00:16.550578Z",
     "iopub.status.busy": "2021-10-22T10:00:16.549527Z",
     "iopub.status.idle": "2021-10-22T10:00:18.503720Z",
     "shell.execute_reply": "2021-10-22T10:00:18.502889Z",
     "shell.execute_reply.started": "2021-10-22T10:00:16.550525Z"
    }
   },
   "outputs": [],
   "source": [
    "# оценка качества\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in val_data_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.reshape(len(labels), 1)\n",
    "        labels = labels.type(torch.FloatTensor)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        predicted = (torch.sigmoid(outputs.data) > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим новую архитектуру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T10:07:15.776926Z",
     "iopub.status.busy": "2021-10-22T10:07:15.776590Z",
     "iopub.status.idle": "2021-10-22T10:07:15.790121Z",
     "shell.execute_reply": "2021-10-22T10:07:15.789204Z",
     "shell.execute_reply.started": "2021-10-22T10:07:15.776891Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(in_channels=3, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer2 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer3 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv_layer4 = nn.Conv2d(in_channels=256, out_channels=4036, kernel_size=7)\n",
    "        self.pooling_layer1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.pooling_layer2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.pooling_layer3 = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "        \n",
    "        self.linear_layer1 = nn.Linear(in_features=4036, out_features=1000)\n",
    "        self.linear_layer2 = nn.Linear(in_features=1000, out_features=1)\n",
    "\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        output_1 = self.relu(self.conv_layer1(x))\n",
    "        output_2 = self.pooling_layer1(output_1)\n",
    "        output_3 = self.relu(self.conv_layer2(output_2))\n",
    "        output_4 = self.pooling_layer2(output_3)\n",
    "        output_5 = self.relu(self.conv_layer3(output_4))\n",
    "        output_6 = self.pooling_layer3(output_5)\n",
    "        output_7 = self.relu(self.conv_layer4(output_6))\n",
    "        output_8 = torch.flatten(output_7, 1)\n",
    "        \n",
    "        output_9 = self.linear_layer1(output_8)\n",
    "        output = self.linear_layer2(output_9)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T10:07:29.715758Z",
     "iopub.status.busy": "2021-10-22T10:07:29.715426Z",
     "iopub.status.idle": "2021-10-22T10:07:30.185855Z",
     "shell.execute_reply": "2021-10-22T10:07:30.184951Z",
     "shell.execute_reply.started": "2021-10-22T10:07:29.715711Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T10:07:43.083823Z",
     "iopub.status.busy": "2021-10-22T10:07:43.083240Z",
     "iopub.status.idle": "2021-10-22T10:07:43.089095Z",
     "shell.execute_reply": "2021-10-22T10:07:43.088006Z",
     "shell.execute_reply.started": "2021-10-22T10:07:43.083787Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T10:07:50.858530Z",
     "iopub.status.busy": "2021-10-22T10:07:50.858250Z",
     "iopub.status.idle": "2021-10-22T10:38:26.421963Z",
     "shell.execute_reply": "2021-10-22T10:38:26.420411Z",
     "shell.execute_reply.started": "2021-10-22T10:07:50.858500Z"
    }
   },
   "outputs": [],
   "source": [
    "# обучение\n",
    "torch.manual_seed(10)\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "total_step = len(train_data_loader)\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_data_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.reshape(len(labels), 1)\n",
    "        labels = labels.type(torch.FloatTensor)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "               .format(epoch+1, epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-22T10:38:26.425473Z",
     "iopub.status.busy": "2021-10-22T10:38:26.425098Z",
     "iopub.status.idle": "2021-10-22T10:39:30.213699Z",
     "shell.execute_reply": "2021-10-22T10:39:30.212732Z",
     "shell.execute_reply.started": "2021-10-22T10:38:26.425424Z"
    }
   },
   "outputs": [],
   "source": [
    "# оценка качества\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in val_data_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.reshape(len(labels), 1)\n",
    "        labels = labels.type(torch.FloatTensor)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        predicted = (torch.sigmoid(outputs.data) > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
